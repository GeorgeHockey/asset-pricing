{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following exactly the Germans' code -- found their mistake!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats\n",
    "from numpy.linalg import inv\n",
    "import pandas_datareader as pdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required data\n",
    "ff_reversal = pdr.get_data_famafrench(\"F-F_ST_Reversal_Factor\", start=\"1963-07\", end=\"2020-06\")[0] * (1/100)\n",
    "ff_momentum = pdr.get_data_famafrench(\"F-F_Momentum_Factor\", start=\"1963-07\", end=\"2020-06\")[0] * (1/100)\n",
    "ff_factors = pdr.get_data_famafrench(\"F-F_Research_Data_Factors\", start=\"1963-07\", end=\"2020-06\")[0] * (1/100)\n",
    "ff_5_factors = pdr.get_data_famafrench(\"F-F_Research_Data_5_Factors_2x3\", start=\"1963-07\", end=\"2020-06\")[0] * (1/100)\n",
    "ff_portfolios = pdr.get_data_famafrench(\"25_Portfolios_5x5\", start=\"1963-07\", end=\"2020-06\")[0] * (1/100)\n",
    "\n",
    "# Portfolio returns must be excess for GRS\n",
    "ff_portfolios_excess = ff_portfolios.sub(ff_factors[\"RF\"], axis=0)\n",
    "\n",
    "# Remove RF from dataframes\n",
    "ff_5_factors = ff_5_factors.drop(columns=[\"RF\"])\n",
    "ff_factors = ff_factors.drop(columns=[\"RF\"])\n",
    "\n",
    "#For 5 Factors\n",
    "ff_5_factors_constant = sm.add_constant(ff_5_factors)\n",
    "\n",
    "# For 3 Factors + Momentum\n",
    "ff_3_factors_mom = pd.concat([ff_factors[\"Mkt-RF\"], ff_factors[\"SMB\"], ff_factors[\"HML\"], ff_momentum], axis=1)\n",
    "ff_3_factors_mom_constant = sm.add_constant(ff_3_factors_mom)\n",
    "\n",
    "# For 3 Factors + reversal\n",
    "ff_3_factors_rev = pd.concat([ff_factors[\"Mkt-RF\"], ff_factors[\"SMB\"], ff_factors[\"HML\"], ff_reversal], axis=1)\n",
    "ff_3_factors_rev_constant = sm.add_constant(ff_3_factors_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Mkt-RF     SMB     HML\n",
       "Date                           \n",
       "1963-07 -0.0039 -0.0049 -0.0094\n",
       "1963-08  0.0507 -0.0102  0.0182\n",
       "1963-09 -0.0157 -0.0031  0.0017\n",
       "1963-10  0.0253 -0.0057 -0.0004\n",
       "1963-11 -0.0085 -0.0115  0.0170\n",
       "...         ...     ...     ...\n",
       "2020-02 -0.0813  0.0102 -0.0392\n",
       "2020-03 -0.1338 -0.0503 -0.1396\n",
       "2020-04  0.1365  0.0275 -0.0139\n",
       "2020-05  0.0558  0.0249 -0.0505\n",
       "2020-06  0.0246  0.0271 -0.0235\n",
       "\n",
       "[684 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mkt-RF</th>\n      <th>SMB</th>\n      <th>HML</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1963-07</th>\n      <td>-0.0039</td>\n      <td>-0.0049</td>\n      <td>-0.0094</td>\n    </tr>\n    <tr>\n      <th>1963-08</th>\n      <td>0.0507</td>\n      <td>-0.0102</td>\n      <td>0.0182</td>\n    </tr>\n    <tr>\n      <th>1963-09</th>\n      <td>-0.0157</td>\n      <td>-0.0031</td>\n      <td>0.0017</td>\n    </tr>\n    <tr>\n      <th>1963-10</th>\n      <td>0.0253</td>\n      <td>-0.0057</td>\n      <td>-0.0004</td>\n    </tr>\n    <tr>\n      <th>1963-11</th>\n      <td>-0.0085</td>\n      <td>-0.0115</td>\n      <td>0.0170</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2020-02</th>\n      <td>-0.0813</td>\n      <td>0.0102</td>\n      <td>-0.0392</td>\n    </tr>\n    <tr>\n      <th>2020-03</th>\n      <td>-0.1338</td>\n      <td>-0.0503</td>\n      <td>-0.1396</td>\n    </tr>\n    <tr>\n      <th>2020-04</th>\n      <td>0.1365</td>\n      <td>0.0275</td>\n      <td>-0.0139</td>\n    </tr>\n    <tr>\n      <th>2020-05</th>\n      <td>0.0558</td>\n      <td>0.0249</td>\n      <td>-0.0505</td>\n    </tr>\n    <tr>\n      <th>2020-06</th>\n      <td>0.0246</td>\n      <td>0.0271</td>\n      <td>-0.0235</td>\n    </tr>\n  </tbody>\n</table>\n<p>684 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "ff_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_GRS(alpha_vector, factor_dataframe, asset_returns):\n",
    "    gen_cov = factor_dataframe.cov()\n",
    "    generalized_sharpe = factor_dataframe.mean().T @ inv(gen_cov) @ factor_dataframe.mean()     #Cochrane 2005, p.217\n",
    "    cov = asset_returns.cov()\n",
    "    if isinstance(alpha_vector, list):\n",
    "        alpha_vector = np.array(alpha_vector)\n",
    "    #Calc GRS\n",
    "    df = len(asset_returns) - len(asset_returns.columns) - len(factor_dataframe.columns) # T - N - K     (N = number of assets, K = number of factors)\n",
    "    N = len(asset_returns.columns)\n",
    "    GRS = (df/ N) * ((alpha_vector.T @ inv(cov) @ alpha_vector) / (1+ generalized_sharpe))\n",
    "    p = 1-scipy.stats.f.cdf(GRS, len(asset_returns.columns), df) #find p-value of F test statistic\n",
    "    return GRS, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_3 = []\n",
    "\n",
    "alphas_5 = []\n",
    "alphas_mom = []\n",
    "alphas_rev = []\n",
    "\n",
    "for columns in ff_portfolios_excess:\n",
    "\n",
    "    x = sm.add_constant(ff_factors)\n",
    "    res = sm.OLS(ff_portfolios_excess[columns],x).fit()\n",
    "    alphas_3.append(res.params[0])\n",
    "\n",
    "    x = sm.add_constant(ff_5_factors)\n",
    "    res = sm.OLS(ff_portfolios_excess[columns],x).fit()\n",
    "    alphas_5.append(res.params[0])\n",
    "\n",
    "    x = sm.add_constant(ff_3_factors_mom)\n",
    "    res = sm.OLS(ff_portfolios_excess[columns],x).fit()\n",
    "    alphas_mom.append(res.params[0])\n",
    "\n",
    "    x = sm.add_constant(ff_3_factors_rev)\n",
    "    res = sm.OLS(ff_portfolios_excess[columns],x).fit()\n",
    "    alphas_rev.append(res.params[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3.4774738491444026, 3.765973921598942e-08)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "## NOT NEEDED HERE: for comparison with 3d - 3 factor non-investment portfolio.\n",
    "calc_GRS(alphas_3,ff_factors,ff_portfolios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2.8519056165283048, 5.697332044030112e-06)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "calc_GRS(alphas_5,ff_5_factors,ff_portfolios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2.7369360415319433, 1.3843179106909353e-05)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "calc_GRS(alphas_mom,ff_3_factors_mom,ff_portfolios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3.605381005273485, 1.3149262900746805e-08)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "calc_GRS(alphas_rev,ff_3_factors_rev,ff_portfolios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Factor premia and pricing error for the 5 factor model are:\nPricing error: 0    0.009395\ndtype: float64 Premia: lambda_mkt   -0.0042\nlambda_SMB    0.0026\nlambda_HML    0.0022\nlambda_RMW    0.0044\nlambda_CMA    0.0002\ndtype: float64\nt-stats:    t_alpha  t_mkt  t_SMB  t_HML  t_RMW  t_CMA\n0     3.38  -1.28   2.15    1.9   2.54   0.11\n"
     ]
    }
   ],
   "source": [
    "## 5 FACTOR MODEL\n",
    "\n",
    "B_mkt = []\n",
    "B_SMB = []\n",
    "B_HML = []\n",
    "B_RMW = []\n",
    "B_CMA = []\n",
    "\n",
    "#Step one:\n",
    "for column in ff_portfolios_excess:\n",
    "    x = ff_5_factors_constant\n",
    "    y = ff_portfolios_excess[column]\n",
    "    reg = sm.OLS(y,x).fit()\n",
    "    B_mkt.append(reg.params[1])\n",
    "    B_SMB.append(reg.params[2])\n",
    "    B_HML.append(reg.params[3])\n",
    "    B_RMW.append(reg.params[4])\n",
    "    B_CMA.append(reg.params[5])\n",
    "\n",
    "B_mkt = pd.DataFrame(np.array(B_mkt))\n",
    "B_SMB = pd.DataFrame(np.array(B_SMB))\n",
    "B_HML = pd.DataFrame(np.array(B_HML))\n",
    "B_RMW = pd.DataFrame(np.array(B_RMW))\n",
    "B_CMA = pd.DataFrame(np.array(B_CMA))\n",
    "\n",
    "betas = pd.concat([B_mkt, B_SMB, B_HML, B_RMW, B_CMA], axis=1)\n",
    "betas.columns = ['B_mkt', \"B_SMB\", 'B_HML', \"B_RMW\", 'B_CMA']\n",
    "betas = sm.add_constant(betas)\n",
    "betas.index = ff_portfolios_excess.T.index\n",
    "\n",
    "alpha = []\n",
    "lambda_mkt = []\n",
    "lambda_SMB = []\n",
    "lambda_HML = []\n",
    "lambda_RMW = []\n",
    "lambda_CMA = []\n",
    "\n",
    "for column in ff_portfolios_excess.T:\n",
    "    x = betas\n",
    "    y = ff_portfolios_excess.T[column]\n",
    "    reg = sm.OLS(y,x).fit()\n",
    "    alpha.append(reg.params[0])\n",
    "    lambda_mkt.append(reg.params[1])\n",
    "    lambda_SMB.append(reg.params[2])\n",
    "    lambda_HML.append(reg.params[3])\n",
    "    lambda_RMW.append(reg.params[4])\n",
    "    lambda_CMA.append(reg.params[5]) #appends the alphas and risk premia for every time period\n",
    "\n",
    "alpha = pd.DataFrame(np.array(alpha))\n",
    "lambda_mkt = pd.DataFrame(np.array(lambda_mkt))\n",
    "lambda_SMB = pd.DataFrame(np.array(lambda_SMB))\n",
    "lambda_HML = pd.DataFrame(np.array(lambda_HML))\n",
    "lambda_RMW = pd.DataFrame(np.array(lambda_RMW))\n",
    "lambda_CMA = pd.DataFrame(np.array(lambda_CMA))\n",
    "\n",
    "lambdas = pd.concat([lambda_mkt, lambda_SMB, lambda_HML, lambda_RMW, lambda_CMA], axis=1)\n",
    "lambdas.columns = ['lambda_mkt', \"lambda_SMB\", 'lambda_HML', \"lambda_RMW\", 'lambda_CMA']\n",
    "\n",
    "params = [alpha, lambda_mkt, lambda_SMB, lambda_HML, lambda_RMW, lambda_CMA]\n",
    "\n",
    "variances = []\n",
    "\n",
    "for i in params:\n",
    "    var = ((i.sub(i.mean(), axis=1)) ** 2).sum() / (len(i) ** 2)\n",
    "    variances.append(var)\n",
    "\n",
    "variances = pd.DataFrame(np.array(variances)).T\n",
    "variances.columns = ['alpha', 'lambda_mkt', 'lambda_SMB', 'lambda_HML', 'lambda_RMW', 'lambda_CMA']\n",
    "\n",
    "#Shanken Adjustment\n",
    "adjustment = (1 + (lambdas.mean().T @ inv(ff_5_factors.cov()) @ lambdas.mean()))            # DO we not need the applicative adjustment too (check with prof, Cochrane 2005 p.223)\n",
    "#Adjusted variances\n",
    "variances = variances * adjustment\n",
    "\n",
    "#t-tests\n",
    "t_alpha = alpha.mean() / np.sqrt(variances['alpha'])\n",
    "t_mkt = lambda_mkt.mean() / np.sqrt(variances['lambda_mkt'])\n",
    "t_SMB = lambda_SMB.mean() / np.sqrt(variances['lambda_SMB'])\n",
    "t_HML = lambda_HML.mean() / np.sqrt(variances['lambda_HML'])\n",
    "t_RMW = lambda_RMW.mean() / np.sqrt(variances['lambda_RMW'])\n",
    "t_CMA = lambda_CMA.mean() / np.sqrt(variances['lambda_CMA'])\n",
    "t_stats = pd.concat([t_alpha, t_mkt, t_SMB, t_HML, t_RMW, t_CMA], axis=1)\n",
    "t_stats.columns = ['t_alpha', 't_mkt', 't_SMB', 't_HML', 't_RMW', 't_CMA']\n",
    "t_stats = np.round(t_stats,2)\n",
    "\n",
    "print(\"Factor premia and pricing error for the 5 factor model are:\")\n",
    "print(\"Pricing error:\", alpha.mean(), \"Premia:\", np.round(lambdas.mean(),4))\n",
    "print(\"t-stats:\", t_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Factor premia and pricing error for the 3 and mom factor model are:\nPricing error: 0    0.004039\ndtype: float64 Premia: lambda_mkt    0.0020\nlambda_SMB    0.0015\nlambda_HML    0.0031\nlambda_MOM    0.0249\ndtype: float64\nt-stats:    t_alpha  t_mkt  t_SMB  t_HML  t_MOM\n0     1.11   0.47   1.01   2.29   2.98\n"
     ]
    }
   ],
   "source": [
    "## 3 FACTOR MODEL + momentum\n",
    "\n",
    "B_mkt = []\n",
    "B_SMB = []\n",
    "B_HML = []\n",
    "B_MOM = []\n",
    "\n",
    "#Step one:\n",
    "for column in ff_portfolios_excess:\n",
    "    x = ff_3_factors_mom_constant\n",
    "    y = ff_portfolios_excess[column]\n",
    "    reg = sm.OLS(y,x).fit()\n",
    "    B_mkt.append(reg.params[1])\n",
    "    B_SMB.append(reg.params[2])\n",
    "    B_HML.append(reg.params[3])\n",
    "    B_MOM.append(reg.params[4])\n",
    "  \n",
    "\n",
    "B_mkt = pd.DataFrame(np.array(B_mkt))\n",
    "B_SMB = pd.DataFrame(np.array(B_SMB))\n",
    "B_HML = pd.DataFrame(np.array(B_HML))\n",
    "B_MOM = pd.DataFrame(np.array(B_MOM))\n",
    "\n",
    "\n",
    "betas = pd.concat([B_mkt, B_SMB, B_HML, B_MOM], axis=1)\n",
    "betas.columns = ['B_mkt', \"B_SMB\", 'B_HML', 'B_MOM']\n",
    "betas = sm.add_constant(betas)\n",
    "betas.index = ff_portfolios_excess.T.index\n",
    "\n",
    "alpha = []\n",
    "lambda_mkt = []\n",
    "lambda_SMB = []\n",
    "lambda_HML = []\n",
    "lambda_MOM = []\n",
    "\n",
    "for column in ff_portfolios_excess.T:\n",
    "    x = betas\n",
    "    y = ff_portfolios_excess.T[column]\n",
    "    reg = sm.OLS(y,x).fit()\n",
    "    alpha.append(reg.params[0])\n",
    "    lambda_mkt.append(reg.params[1])\n",
    "    lambda_SMB.append(reg.params[2])\n",
    "    lambda_HML.append(reg.params[3])\n",
    "    lambda_MOM.append(reg.params[4])  #appends the alphas and risk premia for every time period\n",
    "\n",
    "alpha = pd.DataFrame(np.array(alpha))\n",
    "lambda_mkt = pd.DataFrame(np.array(lambda_mkt))\n",
    "lambda_SMB = pd.DataFrame(np.array(lambda_SMB))\n",
    "lambda_HML = pd.DataFrame(np.array(lambda_HML))\n",
    "lambda_MOM = pd.DataFrame(np.array(lambda_MOM))\n",
    "\n",
    "lambdas = pd.concat([lambda_mkt, lambda_SMB, lambda_HML, lambda_MOM], axis=1)\n",
    "lambdas.columns = ['lambda_mkt', \"lambda_SMB\", 'lambda_HML', \"lambda_MOM\"]\n",
    "\n",
    "params = [alpha, lambda_mkt, lambda_SMB, lambda_HML, lambda_MOM]\n",
    "\n",
    "variances = []\n",
    "\n",
    "for i in params:\n",
    "    var = ((i.sub(i.mean(), axis=1)) ** 2).sum() / (len(i) ** 2)\n",
    "    variances.append(var)\n",
    "\n",
    "variances = pd.DataFrame(np.array(variances)).T\n",
    "variances.columns = ['alpha', 'lambda_mkt', 'lambda_SMB', 'lambda_HML', 'lambda_MOM']\n",
    "\n",
    "#Shanken Adjustment\n",
    "adjustment = (1 + (lambdas.mean().T @ inv(ff_3_factors_mom.cov()) @ lambdas.mean()))            # DO we not need the applicative adjustment too (check with prof, Cochrane 2005 p.223)\n",
    "#Adjusted variances\n",
    "variances = variances * adjustment\n",
    "\n",
    "#t-tests\n",
    "t_alpha = alpha.mean() / np.sqrt(variances['alpha'])\n",
    "t_mkt = lambda_mkt.mean() / np.sqrt(variances['lambda_mkt'])\n",
    "t_SMB = lambda_SMB.mean() / np.sqrt(variances['lambda_SMB'])\n",
    "t_HML = lambda_HML.mean() / np.sqrt(variances['lambda_HML'])\n",
    "t_MOM = lambda_MOM.mean() / np.sqrt(variances['lambda_MOM'])\n",
    "t_stats = pd.concat([t_alpha, t_mkt, t_SMB, t_HML, t_MOM], axis=1)\n",
    "t_stats.columns = ['t_alpha', 't_mkt', 't_SMB', 't_HML', 't_MOM']\n",
    "t_stats = np.round(t_stats,2)\n",
    "\n",
    "print(\"Factor premia and pricing error for the 3 and mom factor model are:\")\n",
    "print(\"Pricing error:\", alpha.mean(), \"Premia:\", np.round(lambdas.mean(),4))\n",
    "print(\"t-stats:\", t_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "const    0.119107\n",
       "B_mkt   -0.111711\n",
       "B_SMB    0.036199\n",
       "B_HML   -0.023165\n",
       "B_MOM   -0.400634\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "reg.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Factor premia and pricing error for the 3 and rev factor model are:\nPricing error: 0    0.011386\ndtype: float64 Premia: lambda_mkt   -0.0057\nlambda_SMB    0.0014\nlambda_HML    0.0029\nlambda_REV   -0.0071\ndtype: float64\nt-stats:    t_alpha  t_mkt  t_SMB  t_HML  t_REV\n0     4.25  -1.77   1.16   2.45  -1.53\n"
     ]
    }
   ],
   "source": [
    "## 3 FACTOR MODEL + reversal\n",
    "\n",
    "B_mkt = []\n",
    "B_SMB = []\n",
    "B_HML = []\n",
    "B_REV = []\n",
    "\n",
    "#Step one:\n",
    "for column in ff_portfolios_excess:\n",
    "    x = ff_3_factors_rev_constant\n",
    "    y = ff_portfolios_excess[column]\n",
    "    reg = sm.OLS(y,x).fit()\n",
    "    B_mkt.append(reg.params[1])\n",
    "    B_SMB.append(reg.params[2])\n",
    "    B_HML.append(reg.params[3])\n",
    "    B_REV.append(reg.params[4])\n",
    "  \n",
    "\n",
    "B_mkt = pd.DataFrame(np.array(B_mkt))\n",
    "B_SMB = pd.DataFrame(np.array(B_SMB))\n",
    "B_HML = pd.DataFrame(np.array(B_HML))\n",
    "B_REV = pd.DataFrame(np.array(B_REV))\n",
    "\n",
    "\n",
    "betas = pd.concat([B_mkt, B_SMB, B_HML, B_REV], axis=1)\n",
    "betas.columns = ['B_mkt', \"B_SMB\", 'B_HML', 'B_REV']\n",
    "betas = sm.add_constant(betas)\n",
    "betas.index = ff_portfolios_excess.T.index\n",
    "\n",
    "alpha = []\n",
    "lambda_mkt = []\n",
    "lambda_SMB = []\n",
    "lambda_HML = []\n",
    "lambda_REV = []\n",
    "\n",
    "for column in ff_portfolios_excess.T:\n",
    "    x = betas\n",
    "    y = ff_portfolios_excess.T[column]\n",
    "    reg = sm.OLS(y,x).fit()\n",
    "    alpha.append(reg.params[0])\n",
    "    lambda_mkt.append(reg.params[1])\n",
    "    lambda_SMB.append(reg.params[2])\n",
    "    lambda_HML.append(reg.params[3])\n",
    "    lambda_REV.append(reg.params[4])  #appends the alphas and risk premia for every time period\n",
    "\n",
    "alpha = pd.DataFrame(np.array(alpha))\n",
    "lambda_mkt = pd.DataFrame(np.array(lambda_mkt))\n",
    "lambda_SMB = pd.DataFrame(np.array(lambda_SMB))\n",
    "lambda_HML = pd.DataFrame(np.array(lambda_HML))\n",
    "lambda_REV = pd.DataFrame(np.array(lambda_REV))\n",
    "\n",
    "lambdas = pd.concat([lambda_mkt, lambda_SMB, lambda_HML, lambda_REV], axis=1)\n",
    "lambdas.columns = ['lambda_mkt', \"lambda_SMB\", 'lambda_HML', \"lambda_REV\"]\n",
    "\n",
    "params = [alpha, lambda_mkt, lambda_SMB, lambda_HML, lambda_REV]\n",
    "\n",
    "variances = []\n",
    "\n",
    "for i in params:\n",
    "    var = ((i.sub(i.mean(), axis=1)) ** 2).sum() / (len(i) ** 2)\n",
    "    variances.append(var)\n",
    "\n",
    "variances = pd.DataFrame(np.array(variances)).T\n",
    "variances.columns = ['alpha', 'lambda_mkt', 'lambda_SMB', 'lambda_HML', 'lambda_REV']\n",
    "\n",
    "#Shanken Adjustment\n",
    "adjustment = (1 + (lambdas.mean().T @ inv(ff_3_factors_rev.cov()) @ lambdas.mean()))            # DO we not need the applicative adjustment too (check with prof, Cochrane 2005 p.223)\n",
    "#Adjusted variances\n",
    "variances = variances * adjustment\n",
    "\n",
    "#t-tests\n",
    "t_alpha = alpha.mean() / np.sqrt(variances['alpha'])\n",
    "t_mkt = lambda_mkt.mean() / np.sqrt(variances['lambda_mkt'])\n",
    "t_SMB = lambda_SMB.mean() / np.sqrt(variances['lambda_SMB'])\n",
    "t_HML = lambda_HML.mean() / np.sqrt(variances['lambda_HML'])\n",
    "t_REV = lambda_REV.mean() / np.sqrt(variances['lambda_REV'])\n",
    "t_stats = pd.concat([t_alpha, t_mkt, t_SMB, t_HML, t_REV], axis=1)\n",
    "t_stats.columns = ['t_alpha', 't_mkt', 't_SMB', 't_HML', 't_REV']\n",
    "t_stats = np.round(t_stats,2)\n",
    "\n",
    "print(\"Factor premia and pricing error for the 3 and rev factor model are:\")\n",
    "print(\"Pricing error:\", alpha.mean(), \"Premia:\", np.round(lambdas.mean(),4))\n",
    "print(\"t-stats:\", t_stats)"
   ]
  }
 ]
}